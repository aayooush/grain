{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ufbgPooUPJr"
   },
   "source": [
    "# Advanced `Dataset` usage\n",
    "\n",
    "If you decided to use `Dataset` APIs, there's a good chance you want to do one or more processing steps described in this section, especially if working on data ingestion for generative model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GfA_bctscNyV"
   },
   "source": [
    "## Mixing datasets\n",
    "\n",
    "`Dataset` allows mixing multiple data sources with potentially different transformations. There's two different ways of mixing `Dataset`s: `MapDataset.mix` and `IterDataset.mix`. If the mixed `Datasets` are sparse (e.g. one of the mixture components needs to be filtered) use `IterDataset.mix`, otherwise use `MapDataset.mix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFw1tjvkP3wb"
   },
   "outputs": [],
   "source": [
    "# @test {\"output\": \"ignore\"}\n",
    "!pip install grain\n",
    "# @test {\"output\": \"ignore\"}\n",
    "!pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fwvOt8-cqcQn"
   },
   "outputs": [],
   "source": [
    "import grain.python as grain\n",
    "import pprint\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e8ROZXhtwOx3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed dataset length = 6728\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "tfds.core.DatasetInfo.file_format = tfds.core.file_adapters.FileFormat.ARRAY_RECORD\n",
    "# This particular dataset mixes medical images with hand written numbers,\n",
    "# probably not useful but allows to illustrate the API on small datasets.\n",
    "source1 = tfds.data_source(name=\"pneumonia_mnist\", split='train')\n",
    "source2 = tfds.data_source(name=\"mnist\", split='train')\n",
    "ds1 = grain.MapDataset.source(source1).map(lambda features: features[\"image\"])\n",
    "ds2 = grain.MapDataset.source(source2).map(lambda features: features[\"image\"])\n",
    "ds = grain.MapDataset.mix([ds1, ds2], weights=[0.7, 0.3])\n",
    "print(f\"Mixed dataset length = {len(ds)}\")\n",
    "pprint.pprint(np.shape(ds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crR2FZ1Gf6-O"
   },
   "source": [
    "If filtering inputs to the mixture, use `IterDataset.mix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "DTmUbvK4r8T8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "source1 = tfds.data_source(name=\"pneumonia_mnist\", split='train')\n",
    "source2 = tfds.data_source(name=\"mnist\", split='train')\n",
    "ds1 = grain.MapDataset.source(source1).filter(lambda features: int(features[\"label\"]) == 1).to_iter_dataset()\n",
    "ds2 = grain.MapDataset.source(source2).filter(lambda features: int(features[\"label\"]) > 4).to_iter_dataset()\n",
    "\n",
    "ds = grain.IterDataset.mix([ds1, ds2], weights=[0.7, 0.3]).map(\n",
    "    lambda features: features[\"image\"]\n",
    ")\n",
    "pprint.pprint(np.shape(next(iter(ds))))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "jupytext": {
   "formats": "ipynb,md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
